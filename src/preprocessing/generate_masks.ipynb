{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a part of motokimura's baseline solution for the [Solafune Identifying Deforestation Drivers competition](https://solafune.com/competitions/68ad4759-4686-4bb3-94b8-7063f755b43d?menu=about&tab=overview).\n",
    "See https://github.com/motokimura/solafune_deforestation_baseline for the complete code.\n",
    "\n",
    "> cf. @solafune (https://solafune.com) Use for any purpose other than participation in the competition or commercial use is prohibited. If you would like to use them for any of the above purposes, please contact us.\n",
    "\n",
    "### Description\n",
    "\n",
    "This notebook generates segmentation masks for the training images and save them as `.npy` files.\n",
    "These files are used as training labels (see https://github.com/motokimura/solafune_deforestation_baseline for the training code).\n",
    "\n",
    "Each `.npy` file contains a numpy array of shape (4, 1024, 1024) for the four classes (`grassland_shrubland`, `logging`, `mining`, and `plantation`).\n",
    "The pixels with value 255 are considered to be the corresponding class.\n",
    "\n",
    "```\n",
    "data/\n",
    "├── train_masks/\n",
    "│   ├── train_0.npy\n",
    "│   ├── train_1.npy\n",
    "│   ├── train_2.npy\n",
    "│   ├── ...\n",
    "```\n",
    "\n",
    "The notebook also saves the visualization of the masks along with the RGB image as a png file.\n",
    "These files are just for visualization (not used for training the model).\n",
    "\n",
    "```\n",
    "data/\n",
    "├── vis_train/\n",
    "│   ├── train_0.png\n",
    "│   ├── train_1.png\n",
    "│   ├── train_2.png\n",
    "│   ├── ...\n",
    "```\n",
    "\n",
    "### Requirements\n",
    "\n",
    "#### Datasets\n",
    "\n",
    "Download the datasets and organize them as follows:\n",
    "\n",
    "```\n",
    "data/\n",
    "├── evaluation_images/\n",
    "│   ├── evaluation_0.tif\n",
    "│   ├── evaluation_1.tif\n",
    "│   ├── evaluation_2.tif\n",
    "│   ├── ...\n",
    "├── train_images/\n",
    "│   ├── train_0.tif\n",
    "│   ├── train_1.tif\n",
    "│   ├── train_2.tif\n",
    "│   ├── ...\n",
    "├── train_annotations.json\n",
    "```\n",
    "\n",
    "#### Libraries\n",
    "\n",
    "Please install the python packages imported the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [00:00<00:00, 109120.10it/s]\n"
     ]
    }
   ],
   "source": [
    "train_file_names = [f\"train_{i}.tif\" for i in range(176)]  # train_0.tif ~ train_175.tif\n",
    "class_names = [\"grassland_shrubland\", \"logging\", \"mining\", \"plantation\"]\n",
    "\n",
    "with open(data_dir / \"train_annotations.json\", \"r\") as f:\n",
    "    raw_annotations = json.load(f)\n",
    "\n",
    "annotations: dict[str, dict[str, list[list[float]]]] = {}  # file_name -> class_name -> polygons\n",
    "for fn in tqdm(train_file_names):\n",
    "    ann: dict[str, list[list[float]]] = {}  # class_name -> polygons\n",
    "    for class_name in class_names:\n",
    "        ann[class_name] = []\n",
    "\n",
    "    for tmp_img in raw_annotations[\"images\"]:\n",
    "        if tmp_img[\"file_name\"] == fn:\n",
    "            for tmp_ann in tmp_img[\"annotations\"]:\n",
    "                ann[tmp_ann[\"class\"]].append(tmp_ann[\"segmentation\"])\n",
    "\n",
    "    annotations[fn] = ann\n",
    "\n",
    "#print(annotations[\"train_0.tif\"])\n",
    "# {'grassland_shrubland': [], 'logging': [], 'mining': [], 'plantation': [[0.0, 449.0, 9.0, 454.0, 18.0, 461.0, 26.0, 468.0, 33.0, 475.0, 40.0, 477.0, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [00:00<00:00, 524.70it/s]\n"
     ]
    }
   ],
   "source": [
    "mask_save_dir = data_dir / \"train_masks\"\n",
    "mask_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for fn in tqdm(train_file_names):\n",
    "    mask = np.zeros((4, 1024, 1024), dtype=np.uint8)\n",
    "    anns = annotations[fn]\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        polygons = anns[class_name]\n",
    "        cv2.fillPoly(mask[class_idx], [np.array(poly).astype(np.int32).reshape(-1, 2) for poly in polygons], 255)\n",
    "\n",
    "    np.save(mask_save_dir / fn.replace(\".tif\", \".npy\"), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 176/176 [00:23<00:00,  7.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# visualize masks and save as a png file along with the RGB image\n",
    "\n",
    "vis_save_dir = data_dir / \"vis_train\"\n",
    "vis_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for fn in tqdm(train_file_names):\n",
    "    mask = np.load(mask_save_dir / fn.replace(\".tif\", \".npy\"))  # (4, 1024, 1024)\n",
    "    vis_masks = [np.zeros((1024, 1024, 3), dtype=np.uint8) for _ in range(4)]  # 4: (glassland_shrubland, logging, mining, plantation)\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        vis_masks[class_idx][mask[class_idx] > 0] = np.array([255, 0, 0])  # blue\n",
    "        # put class_name as text on the mask\n",
    "        cv2.putText(vis_masks[class_idx], class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    vis_image = tifffile.imread(data_dir / \"train_images\" / fn)\n",
    "    vis_image = vis_image[:, :, [1, 2, 3]]  # extract BGR channels (B2, B3, and B4 band of Sentinel-2)\n",
    "    vis_image = np.nan_to_num(vis_image, nan=0)\n",
    "    vis_image = (vis_image / 8).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "    partition = np.ones((1024, 5, 3), dtype=np.uint8) * 255  # white partition\n",
    "    vis = np.concatenate([vis_image, partition, vis_masks[0], partition, vis_masks[1], partition, vis_masks[2], partition, vis_masks[3]], axis=1)\n",
    "    cv2.imwrite(vis_save_dir / fn.replace(\".tif\", \".png\"), vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
